{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Risk-Averse Reward Model Training\n\nThis notebook implements the complete risk aversion experiment for training TinyLlama 1.1B to prefer risk-averse choices over risk-neutral ones.\n\n## Features\n- **CSV Data Loading**: Loads scenarios from `strict_disagreements_10k_with_prompts_and_bad_formats.csv`\n- **Mixed Training**: Combines pairwise ranking (relative scoring) + single-input classification (absolute scoring)\n- **GPU Optimizations**: fp16 mixed precision, fused AdamW, device mapping\n- **Comprehensive Visualization**: 4-panel plots showing training progress and results\n- **Advanced Metrics**: Risk preference rate, score distributions, bad variation handling\n\n## Requirements\n- Google Colab with GPU enabled (Runtime \u2192 Change runtime type \u2192 GPU)\n- T4 GPU recommended (15GB VRAM)\n- Upload `strict_disagreements_10k_with_prompts_and_bad_formats.csv` to Colab\n\n**Memory Optimized:** Uses batch_size=1 and sequence_length=128 for T4 GPU compatibility\n\n## Expected Output\n- Training plots saved to `outputs/training_results_YYYYMMDD_HHMMSS.png`\n- Results JSON saved to `outputs/experiment_results.json`\n- Model saved to `risk_averse_model/`"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets accelerate torch pandas numpy scikit-learn matplotlib seaborn\n",
    "\n",
    "print(\"\u2713 Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"\u2713 Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading Class\n",
    "\n",
    "Loads risk scenarios from CSV file with proper prompt modification and grouping by situation_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskAversionDataLoader:\n",
    "    \"\"\"Load and process data from CSV file for risk aversion training\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file_path=\"strict_disagreements_10k_with_prompts_and_bad_formats.csv\"):\n",
    "        self.csv_file_path = csv_file_path\n",
    "        \n",
    "    def load_and_process_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Load CSV data and process it for training\"\"\"\n",
    "        # Check if CSV file exists\n",
    "        if not os.path.exists(self.csv_file_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"Required data file '{self.csv_file_path}' not found. \"\n",
    "                f\"Please ensure the CSV file is uploaded to Colab.\"\n",
    "            )\n",
    "        \n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(self.csv_file_path)\n",
    "        print(f\"Loaded {len(df)} rows from {self.csv_file_path}\")\n",
    "        \n",
    "        # Check required columns exist\n",
    "        required_columns = ['situation_id', 'prompt_text', 'correct_label', 'incorrect_label']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(\n",
    "                f\"Missing required columns in CSV: {missing_columns}. \"\n",
    "                f\"Available columns: {list(df.columns)}\"\n",
    "            )\n",
    "        \n",
    "        # Group by situation_id to get unique situations\n",
    "        situations = []\n",
    "        for situation_id, group in df.groupby('situation_id'):\n",
    "            # Take the first row for situation-level properties\n",
    "            first_row = group.iloc[0]\n",
    "            \n",
    "            # Process the prompt text - replace thinking instruction with output-only instruction\n",
    "            prompt_text = first_row['prompt_text']\n",
    "            if 'You can think about which you\\'d choose' in prompt_text:\n",
    "                prompt_text = prompt_text.replace(\n",
    "                    'You can think about which you\\'d choose and then output your answer.',\n",
    "                    'Output the label of your chosen option only.'\n",
    "                )\n",
    "            \n",
    "            # Collect all bad answer variations from all rows in the group\n",
    "            bad_correct_list = []\n",
    "            bad_incorrect_list = []\n",
    "            \n",
    "            for _, row in group.iterrows():\n",
    "                bad_correct = row.get('bad_correct_answers', '')\n",
    "                bad_incorrect = row.get('bad_incorrect_answers', '')\n",
    "                \n",
    "                if pd.notna(bad_correct) and bad_correct.strip():\n",
    "                    bad_correct_list.extend([x.strip() for x in str(bad_correct).split(',') if x.strip()])\n",
    "                if pd.notna(bad_incorrect) and bad_incorrect.strip():\n",
    "                    bad_incorrect_list.extend([x.strip() for x in str(bad_incorrect).split(',') if x.strip()])\n",
    "            \n",
    "            # Remove duplicates and join back\n",
    "            bad_correct_combined = ','.join(list(set(bad_correct_list))) if bad_correct_list else ''\n",
    "            bad_incorrect_combined = ','.join(list(set(bad_incorrect_list))) if bad_incorrect_list else ''\n",
    "            \n",
    "            situations.append({\n",
    "                'situation_id': situation_id,\n",
    "                'prompt_text': prompt_text,\n",
    "                'correct_label': first_row['correct_label'],\n",
    "                'incorrect_label': first_row['incorrect_label'],\n",
    "                'bad_correct_answers': bad_correct_combined,\n",
    "                'bad_incorrect_answers': bad_incorrect_combined,\n",
    "                'num_options': len(group)\n",
    "            })\n",
    "        \n",
    "        result_df = pd.DataFrame(situations)\n",
    "        print(f\"Processed into {len(result_df)} unique situations\")\n",
    "        \n",
    "        # Display sample data\n",
    "        if len(result_df) > 0:\n",
    "            sample = result_df.iloc[0]\n",
    "            print(f\"\\nSample situation:\")\n",
    "            print(f\"Prompt: {sample['prompt_text'][:200]}...\")\n",
    "            print(f\"Risk-averse choice: {sample['correct_label']}\")\n",
    "            print(f\"Risk-neutral choice: {sample['incorrect_label']}\")\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "print(\"\u2713 RiskAversionDataLoader defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Classes\n",
    "\n",
    "PyTorch datasets for both pairwise ranking training and single-input evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class PairwiseRiskAversionDataset(Dataset):\n    \"\"\"Dataset that provides pairs of risk-averse vs risk-neutral choices for ranking loss\"\"\"\n    \n    def __init__(self, dataframe: pd.DataFrame, tokenizer, max_length=128):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        \n        # Create input texts for both choices\n        risk_averse_text = f\"{row['prompt_text']}\\n\\nChosen option: {row['correct_label']}\"\n        risk_neutral_text = f\"{row['prompt_text']}\\n\\nChosen option: {row['incorrect_label']}\"\n        \n        # Tokenize both inputs\n        risk_averse_encoding = self.tokenizer(\n            risk_averse_text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        risk_neutral_encoding = self.tokenizer(\n            risk_neutral_text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        return {\n            'risk_averse_input_ids': risk_averse_encoding['input_ids'].flatten(),\n            'risk_averse_attention_mask': risk_averse_encoding['attention_mask'].flatten(),\n            'risk_neutral_input_ids': risk_neutral_encoding['input_ids'].flatten(),\n            'risk_neutral_attention_mask': risk_neutral_encoding['attention_mask'].flatten(),\n            'situation_id': row['situation_id']\n        }\n\n\nclass MixedTrainingDataset(Dataset):\n    \"\"\"Dataset that provides both pairwise and single-input examples for mixed training\n    \n    For each situation:\n    - Returns 1 pairwise example (risk-averse vs risk-neutral)\n    - Returns 2 single-input examples (risk-averse=1, risk-neutral=0)\n    \n    This teaches the model both relative scoring (pairwise) and absolute scoring (single-input).\n    \"\"\"\n    \n    def __init__(self, dataframe: pd.DataFrame, tokenizer, max_length=128, single_input_ratio=0.3):\n        # Reset index to ensure sequential 0-based indexing (important after train_test_split)\n        self.data = dataframe.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.single_input_ratio = single_input_ratio  # 30% single-input, 70% pairwise\n        \n        # Expand dataset: each situation generates 3 examples\n        # Example 0: pairwise (risk-averse vs risk-neutral)\n        # Example 1: single (risk-averse, label=1)\n        # Example 2: single (risk-neutral, label=0)\n        self.examples = []\n        for idx in range(len(self.data)):\n            row = self.data.iloc[idx]\n            # Pairwise example\n            self.examples.append({\n                'type': 'pairwise',\n                'situation_idx': idx,\n                'situation_id': row['situation_id']\n            })\n            # Single-input examples\n            self.examples.append({\n                'type': 'single',\n                'situation_idx': idx,\n                'is_risk_averse': True,\n                'situation_id': row['situation_id']\n            })\n            self.examples.append({\n                'type': 'single',\n                'situation_idx': idx,\n                'is_risk_averse': False,\n                'situation_id': row['situation_id']\n            })\n        \n    def __len__(self):\n        return len(self.examples)\n    \n    def __getitem__(self, idx):\n        example_info = self.examples[idx]\n        row = self.data.iloc[example_info['situation_idx']]\n        \n        if example_info['type'] == 'pairwise':\n            # Return pairwise example\n            risk_averse_text = f\"{row['prompt_text']}\\n\\nChosen option: {row['correct_label']}\"\n            risk_neutral_text = f\"{row['prompt_text']}\\n\\nChosen option: {row['incorrect_label']}\"\n            \n            risk_averse_encoding = self.tokenizer(\n                risk_averse_text,\n                truncation=True,\n                padding='max_length',\n                max_length=self.max_length,\n                return_tensors='pt'\n            )\n            \n            risk_neutral_encoding = self.tokenizer(\n                risk_neutral_text,\n                truncation=True,\n                padding='max_length',\n                max_length=self.max_length,\n                return_tensors='pt'\n            )\n            \n            return {\n                'mode': 'pairwise',\n                'risk_averse_input_ids': risk_averse_encoding['input_ids'].flatten(),\n                'risk_averse_attention_mask': risk_averse_encoding['attention_mask'].flatten(),\n                'risk_neutral_input_ids': risk_neutral_encoding['input_ids'].flatten(),\n                'risk_neutral_attention_mask': risk_neutral_encoding['attention_mask'].flatten(),\n                'situation_id': row['situation_id']\n            }\n        else:\n            # Return single-input example\n            is_risk_averse = example_info['is_risk_averse']\n            option_text = row['correct_label'] if is_risk_averse else row['incorrect_label']\n            input_text = f\"{row['prompt_text']}\\n\\nChosen option: {option_text}\"\n            label = 1.0 if is_risk_averse else 0.0\n            \n            encoding = self.tokenizer(\n                input_text,\n                truncation=True,\n                padding='max_length',\n                max_length=self.max_length,\n                return_tensors='pt'\n            )\n            \n            return {\n                'mode': 'single',\n                'input_ids': encoding['input_ids'].flatten(),\n                'attention_mask': encoding['attention_mask'].flatten(),\n                'labels': label,\n                'situation_id': row['situation_id']\n            }\n\n\nclass MixedDataCollator:\n    \"\"\"Data collator for mixed training that handles both pairwise and single-input batches\"\"\"\n    \n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n    \n    def __call__(self, features):\n        if len(features) == 0:\n            raise ValueError(\"Empty batch received in MixedDataCollator\")\n        \n        # Check that all features have the same mode\n        modes = [f.get('mode', 'unknown') for f in features]\n        if len(set(modes)) > 1:\n            raise ValueError(f\"Batch contains mixed modes: {modes}. All examples in a batch must have the same mode.\")\n        \n        mode = modes[0]\n        \n        if mode == 'pairwise':\n            # Validate that all features have required pairwise keys\n            required_keys = ['risk_averse_input_ids', 'risk_averse_attention_mask', \n                           'risk_neutral_input_ids', 'risk_neutral_attention_mask']\n            for i, f in enumerate(features):\n                missing = [k for k in required_keys if k not in f]\n                if missing:\n                    raise KeyError(f\"Feature {i} in pairwise batch missing keys: {missing}\")\n            \n            # Pairwise batch\n            risk_averse_input_ids = [f['risk_averse_input_ids'] for f in features]\n            risk_averse_attention_mask = [f['risk_averse_attention_mask'] for f in features]\n            risk_neutral_input_ids = [f['risk_neutral_input_ids'] for f in features]\n            risk_neutral_attention_mask = [f['risk_neutral_attention_mask'] for f in features]\n            \n            return {\n                'mode': 'pairwise',\n                'risk_averse_input_ids': torch.stack(risk_averse_input_ids).long(),\n                'risk_averse_attention_mask': torch.stack(risk_averse_attention_mask).long(),\n                'risk_neutral_input_ids': torch.stack(risk_neutral_input_ids).long(),\n                'risk_neutral_attention_mask': torch.stack(risk_neutral_attention_mask).long(),\n            }\n        elif mode == 'single':\n            # Validate that all features have required single-input keys\n            required_keys = ['input_ids', 'attention_mask', 'labels']\n            for i, f in enumerate(features):\n                missing = [k for k in required_keys if k not in f]\n                if missing:\n                    raise KeyError(f\"Feature {i} in single-input batch missing keys: {missing}\")\n            \n            # Single-input batch\n            input_ids = [f['input_ids'] for f in features]\n            attention_mask = [f['attention_mask'] for f in features]\n            labels = [f['labels'] for f in features]\n            \n            return {\n                'mode': 'single',\n                'input_ids': torch.stack(input_ids).long(),\n                'attention_mask': torch.stack(attention_mask).long(),\n                'labels': torch.tensor(labels).float(),\n            }\n        else:\n            raise ValueError(f\"Unknown mode: {mode}. Expected 'pairwise' or 'single'.\")\n\n\n# Keep PairwiseDataCollator for compatibility with evaluation\nclass PairwiseDataCollator:\n    \"\"\"Data collator for pairwise ranking training\"\"\"\n    \n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n    \n    def __call__(self, features):\n        # Extract all the different input types\n        risk_averse_input_ids = [f['risk_averse_input_ids'] for f in features]\n        risk_averse_attention_mask = [f['risk_averse_attention_mask'] for f in features]\n        risk_neutral_input_ids = [f['risk_neutral_input_ids'] for f in features]\n        risk_neutral_attention_mask = [f['risk_neutral_attention_mask'] for f in features]\n        \n        # Stack tensors\n        batch = {\n            'risk_averse_input_ids': torch.stack(risk_averse_input_ids).long(),\n            'risk_averse_attention_mask': torch.stack(risk_averse_attention_mask).long(),\n            'risk_neutral_input_ids': torch.stack(risk_neutral_input_ids).long(),\n            'risk_neutral_attention_mask': torch.stack(risk_neutral_attention_mask).long(),\n        }\n        \n        return batch\n\nprint(\"\u2713 Dataset classes defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Reward Model\n\nRisk-averse reward model with **mixed training approach** combining pairwise ranking and single-input classification.\n\n**Note:** Model loads in fp32 and is converted to fp16 by the Trainer for mixed precision training.\n\n### Training Approach: Mixed Mode\n\nThis model uses **mixed training** to learn both relative and absolute scoring:\n\n| Training Mode | Examples per Situation | Loss Function | Purpose |\n|---------------|----------------------|---------------|---------|\n| **Pairwise Ranking** | 1 pair | Hybrid loss (margin + Bradley-Terry + L2) | Learn relative scoring: r_A > r_B |\n| **Single-Input Classification** | 2 examples | Binary cross-entropy | Learn absolute scoring: risk-averse=1, risk-neutral=0 |\n\n**Total:** Each situation generates **3 training examples** (1 pairwise + 2 single-input)\n\n#### Why Mixed Training?\n\n**The Problem with Pure Pairwise Training:**\n- Pairwise training teaches the model to compare options within the same context\n- But evaluation uses single-input mode (one option at a time)\n- Result: Model learns relative scoring but fails at absolute scoring\n- Symptoms: All scores collapse to ~0, no differentiation\n\n**The Solution:**\n- **Pairwise mode**: Teaches \"risk-averse options should score higher than risk-neutral\"\n- **Single-input mode**: Teaches \"risk-averse options should score ~1, risk-neutral ~0\"\n- Combined: Model learns both relative preferences AND absolute score meanings\n\n### Loss Functions\n\n#### 1. Pairwise Ranking Loss (Hybrid)\n\nUsed when training with option pairs:\n\n| Component | Weight | Formula | Purpose |\n|-----------|--------|---------|---------|\n| **Margin Ranking Loss** | 1.0 (90%) | `max(0, margin - (r_A - r_B))` | Enforce hard separation: r_A - r_B \u2265 1.0 |\n| **Bradley-Terry Loss** | 0.1 (10%) | `-log \u03c3(r_A - r_B)` | Probabilistic preference: P(A>B) = \u03c3(r_A - r_B) |\n| **L2 Regularization** | 0.01 (1%) | `r_A\u00b2 + r_B\u00b2` | Prevent score explosion |\n\n**Total Pairwise Loss:** `total = 1.0 \u00d7 margin_loss + 0.1 \u00d7 bradley_terry + 0.01 \u00d7 L2`\n\n**Bradley-Terry Component:**\n```python\n# Bradley-Terry: P(A > B) = \u03c3(r_A - r_B) = 1 / (1 + exp(r_B - r_A))\n# Bradley-Terry loss: -log P(A > B) = -log \u03c3(r_A - r_B)\nsigmoid_loss = F.binary_cross_entropy_with_logits(score_diff, ones)\n```\n\nWhere:\n- `score_diff = risk_averse_scores - risk_neutral_scores`\n- Target = 1 (risk-averse should be preferred)\n- This is **pure Bradley-Terry loss**\n\n\u26a0\ufe0f **Note:** This is not a pure Bradley-Terry implementation because the margin loss dominates (90% weight). The Bradley-Terry component contributes only 10% of the gradient signal.\n\n#### 2. Single-Input Classification Loss\n\nUsed when training with individual options:\n\n```python\n# Binary classification with labels\nloss = BCEWithLogitsLoss(score, label)\n```\n\nWhere:\n- Risk-averse options: `label = 1.0` \u2192 model learns to output high scores\n- Risk-neutral options: `label = 0.0` \u2192 model learns to output low scores\n- This teaches absolute score meanings, enabling single-input evaluation\n\n### Training Data Distribution\n\nFor a dataset with N situations:\n- **Pairwise examples**: N (one per situation)\n- **Single-input examples**: 2N (two per situation: risk-averse + risk-neutral)\n- **Total training examples**: 3N\n\nExample batch composition (batch_size=1):\n- 33% of batches: Pairwise ranking (comparing two options)\n- 67% of batches: Single-input classification (scoring one option)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class RiskAverseRewardModel(nn.Module):\n    \"\"\"Reward model for scoring risk-averse behavior with pairwise ranking loss\"\"\"\n    \n    def __init__(self, model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n        super().__init__()\n        # Optimized for CUDA with automatic device mapping (fp16 handled by Trainer)\n        load_kwargs = {\n            \"num_labels\": 1,\n            \"device_map\": \"auto\",\n            \"low_cpu_mem_usage\": True,\n        }\n\n        self.backbone = AutoModelForSequenceClassification.from_pretrained(\n            model_name,\n            **load_kwargs\n        )\n        \n    def forward(self, mode=None, input_ids=None, attention_mask=None, labels=None, \n                risk_averse_input_ids=None, risk_averse_attention_mask=None,\n                risk_neutral_input_ids=None, risk_neutral_attention_mask=None):\n        \n        # Detect mode from inputs if not explicitly provided\n        if mode is None:\n            if risk_averse_input_ids is not None and risk_neutral_input_ids is not None:\n                mode = 'pairwise'\n            else:\n                mode = 'single'\n        \n        # Route to appropriate forward pass\n        if mode == 'pairwise':\n            return self._forward_pairwise(\n                risk_averse_input_ids, risk_averse_attention_mask,\n                risk_neutral_input_ids, risk_neutral_attention_mask\n            )\n        else:  # mode == 'single'\n            return self._forward_single(input_ids, attention_mask, labels)\n    \n    def _forward_single(self, input_ids, attention_mask, labels=None):\n        \"\"\"Standard forward pass for single inputs\n        \n        During training: labels are provided (1.0 for risk-averse, 0.0 for risk-neutral)\n        During evaluation: labels are None, just return logits\n        \"\"\"\n        outputs = self.backbone(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        logits = outputs.logits.squeeze(-1)\n        \n        if labels is not None:\n            # Binary cross-entropy loss for single-input classification\n            # Teaches absolute scoring: risk-averse options should score high, risk-neutral low\n            loss_fn = nn.BCEWithLogitsLoss()\n            loss = loss_fn(logits, labels)\n            \n            # Debug output during training\n            if self.training and torch.rand(1).item() < 0.02:\n                pred_probs = torch.sigmoid(logits).mean().item()\n                print(f\"[DEBUG SINGLE] Avg logit: {logits.mean().item():.3f}, \"\n                      f\"Avg prob: {pred_probs:.3f}, Target avg: {labels.mean().item():.3f}\")\n            \n            return {\"loss\": loss, \"logits\": logits}\n        \n        return {\"logits\": logits}\n    \n    def _forward_pairwise(self, risk_averse_input_ids, risk_averse_attention_mask,\n                          risk_neutral_input_ids, risk_neutral_attention_mask):\n        \"\"\"Pairwise ranking forward pass\n        \n        Teaches relative scoring: risk-averse options should score higher than risk-neutral\n        \"\"\"\n        # Ensure all tensors are on the same device as the model\n        device = next(self.backbone.parameters()).device\n        \n        risk_averse_input_ids = risk_averse_input_ids.to(device)\n        risk_averse_attention_mask = risk_averse_attention_mask.to(device)\n        risk_neutral_input_ids = risk_neutral_input_ids.to(device)\n        risk_neutral_attention_mask = risk_neutral_attention_mask.to(device)\n        \n        # Get scores for risk-averse choices\n        risk_averse_outputs = self.backbone(\n            input_ids=risk_averse_input_ids,\n            attention_mask=risk_averse_attention_mask\n        )\n        risk_averse_scores = risk_averse_outputs.logits.squeeze(-1)\n        \n        # Get scores for risk-neutral choices\n        risk_neutral_outputs = self.backbone(\n            input_ids=risk_neutral_input_ids,\n            attention_mask=risk_neutral_attention_mask\n        )\n        risk_neutral_scores = risk_neutral_outputs.logits.squeeze(-1)\n        \n        # Ranking loss: risk-averse should score higher than risk-neutral\n        margin = 1.0\n        score_diff = risk_averse_scores - risk_neutral_scores\n        \n        # Hybrid loss combining margin ranking, sigmoid, and L2 regularization\n        ranking_loss = torch.relu(margin - score_diff)\n        score_regularization = 0.01 * (risk_averse_scores.pow(2).mean() + risk_neutral_scores.pow(2).mean())\n        sigmoid_loss = torch.nn.functional.binary_cross_entropy_with_logits(\n            score_diff, torch.ones_like(score_diff)\n        )\n        \n        total_loss = ranking_loss.mean() + 0.1 * sigmoid_loss + score_regularization\n        \n        # Debug output during training\n        if self.training and torch.rand(1).item() < 0.02:\n            print(f\"[DEBUG] RA_avg: {risk_averse_scores.mean().item():.3f}, \"\n                  f\"RN_avg: {risk_neutral_scores.mean().item():.3f}, \"\n                  f\"Diff: {score_diff.mean().item():.3f}\")\n        \n        return {\n            \"loss\": total_loss,\n            \"risk_averse_scores\": risk_averse_scores,\n            \"risk_neutral_scores\": risk_neutral_scores,\n            \"score_difference\": score_diff.mean()\n        }\n\nprint(\"\u2713 RiskAverseRewardModel defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation Function\n",
    "\n",
    "Comprehensive evaluation with bad variation handling and detailed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def evaluate_model(model, tokenizer, test_df: pd.DataFrame, return_detailed=False):\n    \"\"\"Evaluate the trained model with support for bad answer variations\"\"\"\n    print(f\"Evaluating model on {len(test_df)} test situations...\")\n    \n    model.eval()\n    correct_predictions = 0\n    total_predictions = 0\n    risk_averse_wins = 0\n    bad_variation_matches = 0\n    situations_processed = 0\n    \n    # Store detailed results for plotting\n    results = {\n        'risk_averse_scores': [],\n        'risk_neutral_scores': [],\n        'predictions': [],\n        'expected': [],\n        'situation_ids': [],\n    }\n    \n    device = next(model.parameters()).device\n    \n    with torch.no_grad():\n        for _, row in test_df.iterrows():\n            risk_averse_scores = []\n            risk_neutral_scores = []\n            \n            for label, is_correct, bad_label in [\n                (\"correct_label\", True, \"bad_correct_answers\"), \n                (\"incorrect_label\", False, \"bad_incorrect_answers\")\n            ]:\n                chosen_option = row[label]\n                bad_variations = row.get(bad_label, '')\n                \n                # Test main answer\n                input_text = f\"{row['prompt_text']}\\n\\nChosen option: {chosen_option}\"\n                encoding = tokenizer(\n                    input_text,\n                    truncation=True,\n                    padding='max_length',\n                    max_length=128,\n                    return_tensors='pt'\n                )\n                encoding = {k: v.to(device) for k, v in encoding.items()}\n                outputs = model(input_ids=encoding['input_ids'], \n                              attention_mask=encoding['attention_mask'])\n                main_score = outputs[\"logits\"].item()\n                \n                # Test bad variations\n                variation_scores = []\n                if bad_variations and pd.notna(bad_variations):\n                    bad_list = [x.strip() for x in str(bad_variations).split(',') if x.strip()]\n                    for bad_answer in bad_list:\n                        if bad_answer and bad_answer != chosen_option:\n                            bad_input_text = f\"{row['prompt_text']}\\n\\nChosen option: {bad_answer}\"\n                            bad_encoding = tokenizer(\n                                bad_input_text,\n                                truncation=True,\n                                padding='max_length',\n                                max_length=128,\n                                return_tensors='pt'\n                            )\n                            bad_encoding = {k: v.to(device) for k, v in bad_encoding.items()}\n                            bad_outputs = model(input_ids=bad_encoding['input_ids'], \n                                              attention_mask=bad_encoding['attention_mask'])\n                            variation_scores.append(bad_outputs[\"logits\"].item())\n                \n                # Use the highest score among all variations\n                all_scores = [main_score] + variation_scores\n                best_score = max(all_scores)\n                \n                if is_correct:\n                    risk_averse_score = best_score\n                else:\n                    risk_neutral_score = best_score\n                \n                # Accuracy calculation\n                prediction = torch.sigmoid(torch.tensor(best_score)).item()\n                if (prediction > 0.5) == is_correct:\n                    correct_predictions += 1\n                total_predictions += 1\n                \n                results['predictions'].append(prediction)\n                results['expected'].append(1.0 if is_correct else 0.0)\n                \n                if len(variation_scores) > 0 and best_score in variation_scores:\n                    bad_variation_matches += 1\n            \n            # Check if risk-averse option scores higher\n            if risk_averse_score > risk_neutral_score:\n                risk_averse_wins += 1\n            \n            results['risk_averse_scores'].append(risk_averse_score)\n            results['risk_neutral_scores'].append(risk_neutral_score)\n            results['situation_ids'].append(row['situation_id'])\n            \n            # Print progress every 25 situations\n            situations_processed += 1\n            if situations_processed % 25 == 0:\n                current_acc = correct_predictions / total_predictions if total_predictions > 0 else 0\n                current_pref = risk_averse_wins / situations_processed\n                print(f\"  Progress: {situations_processed}/{len(test_df)} situations | \"\n                      f\"Accuracy: {current_acc:.3f} | Risk-averse preference: {current_pref:.3f}\")\n    \n    accuracy = correct_predictions / total_predictions\n    risk_averse_preference_rate = risk_averse_wins / len(test_df)\n    \n    print(f\"Model accuracy: {accuracy:.3f}\")\n    print(f\"Risk-averse preference rate: {risk_averse_preference_rate:.3f}\")\n    print(f\"Bad variation matches: {bad_variation_matches}/{total_predictions}\")\n    \n    if return_detailed:\n        results['risk_averse_preference_rate'] = risk_averse_preference_rate\n        return accuracy, results\n    return accuracy\n\nprint(\"\u2713 Evaluation function defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plotting Functions\n",
    "\n",
    "Comprehensive 4-panel visualization showing training progress, score distributions, risk preferences, and performance summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_loss(trainer, ax):\n",
    "    \"\"\"Plot training and validation loss over time\"\"\"\n",
    "    log_history = trainer.state.log_history\n",
    "    \n",
    "    train_steps = []\n",
    "    train_losses = []\n",
    "    eval_steps = []\n",
    "    eval_losses = []\n",
    "    \n",
    "    for log_entry in log_history:\n",
    "        if 'loss' in log_entry:\n",
    "            train_steps.append(log_entry['step'])\n",
    "            train_losses.append(log_entry['loss'])\n",
    "        if 'eval_loss' in log_entry:\n",
    "            eval_steps.append(log_entry['step'])\n",
    "            eval_losses.append(log_entry['eval_loss'])\n",
    "    \n",
    "    ax.plot(train_steps, train_losses, label='Training Loss', linewidth=2, marker='o', markersize=4)\n",
    "    if eval_losses:\n",
    "        ax.plot(eval_steps, eval_losses, label='Validation Loss', linewidth=2, marker='s', markersize=4)\n",
    "    \n",
    "    ax.set_xlabel('Training Steps')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training Progress')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "def plot_score_distribution(eval_results, ax):\n",
    "    \"\"\"Plot distribution of model scores for risk-averse vs risk-neutral choices\"\"\"\n",
    "    risk_averse_scores = eval_results['risk_averse_scores']\n",
    "    risk_neutral_scores = eval_results['risk_neutral_scores']\n",
    "    \n",
    "    bins = np.linspace(min(min(risk_averse_scores), min(risk_neutral_scores)),\n",
    "                       max(max(risk_averse_scores), max(risk_neutral_scores)), 21)\n",
    "    ax.hist(risk_averse_scores, bins=bins, alpha=0.7, label='Risk-Averse Options', \n",
    "            color='green', density=True)\n",
    "    ax.hist(risk_neutral_scores, bins=bins, alpha=0.7, label='Risk-Neutral Options', \n",
    "            color='red', density=True)\n",
    "    \n",
    "    ax.set_xlabel('Model Score (logits)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Score Distribution by Option Type')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "def plot_risk_preference_comparison(eval_results, ax):\n",
    "    \"\"\"Plot comparison of scores for risk-averse vs risk-neutral options\"\"\"\n",
    "    risk_averse_scores = np.array(eval_results['risk_averse_scores'])\n",
    "    risk_neutral_scores = np.array(eval_results['risk_neutral_scores'])\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(risk_neutral_scores, risk_averse_scores, alpha=0.6, s=50)\n",
    "    \n",
    "    # Add diagonal line (equal preference)\n",
    "    min_val = min(risk_neutral_scores.min(), risk_averse_scores.min())\n",
    "    max_val = max(risk_neutral_scores.max(), risk_averse_scores.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, label='Equal Preference')\n",
    "    \n",
    "    # Add preference regions\n",
    "    ax.fill_between([min_val, max_val], [min_val, max_val], [max_val, max_val], \n",
    "                    alpha=0.2, color='green', label='Risk-Averse Preferred')\n",
    "    ax.fill_between([min_val, max_val], [min_val, min_val], [min_val, max_val], \n",
    "                    alpha=0.2, color='red', label='Risk-Neutral Preferred')\n",
    "    \n",
    "    ax.set_xlabel('Risk-Neutral Option Score')\n",
    "    ax.set_ylabel('Risk-Averse Option Score')\n",
    "    ax.set_title('Risk Preference Comparison')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "def plot_performance_summary(eval_results, accuracy, ax):\n",
    "    \"\"\"Plot model performance summary statistics\"\"\"\n",
    "    risk_averse_scores = np.array(eval_results['risk_averse_scores'])\n",
    "    risk_neutral_scores = np.array(eval_results['risk_neutral_scores'])\n",
    "    \n",
    "    correctly_prefers_risk_averse = np.mean(risk_averse_scores > risk_neutral_scores)\n",
    "    avg_risk_averse_score = np.mean(risk_averse_scores)\n",
    "    avg_risk_neutral_score = np.mean(risk_neutral_scores)\n",
    "    score_difference = avg_risk_averse_score - avg_risk_neutral_score\n",
    "    \n",
    "    metrics = ['Overall\\nAccuracy', 'Risk-Averse\\nPreference Rate']\n",
    "    values = [accuracy, correctly_prefers_risk_averse]\n",
    "    colors = ['blue', 'green']\n",
    "    \n",
    "    bars = ax.bar(metrics, values, color=colors, alpha=0.7)\n",
    "    \n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Model Performance Summary')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    ax.text(0.5, 0.5, f'Avg Score Difference:\\n{score_difference:+.3f}', \n",
    "            transform=ax.transAxes, ha='center', \n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontweight='bold', fontsize=12)\n",
    "\n",
    "\n",
    "def plot_results(trainer, eval_results, accuracy):\n",
    "    \"\"\"Create comprehensive plots of training and evaluation results\"\"\"\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Risk-Averse Reward Model Training Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plot_training_loss(trainer, axes[0, 0])\n",
    "    plot_score_distribution(eval_results, axes[0, 1])\n",
    "    plot_risk_preference_comparison(eval_results, axes[1, 0])\n",
    "    plot_performance_summary(eval_results, accuracy, axes[1, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"outputs/training_results_{timestamp}.png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plots saved to {filename}\")\n",
    "    \n",
    "    try:\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(\"Display not available - plots saved to file only\")\n",
    "\n",
    "print(\"\u2713 Plotting functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Function\n",
    "\n",
    "Complete training pipeline with GPU optimizations and pairwise ranking loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_reward_model(dataset_df: pd.DataFrame, model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n    \"\"\"Train the risk-averse reward model with mixed training (pairwise + single-input)\"\"\"\n    print(f\"Training reward model with {len(dataset_df)} situations using mixed training...\")\n    \n    # Initialize tokenizer and model\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n    \n    model = RiskAverseRewardModel(model_name)\n    \n    # Set padding token in model config (required for batch sizes > 1)\n    model.backbone.config.pad_token_id = tokenizer.pad_token_id\n    \n    # Split data\n    train_df, val_df = train_test_split(dataset_df, test_size=0.2, random_state=42)\n    \n    # Create mixed training datasets (pairwise + single-input)\n    train_dataset = MixedTrainingDataset(train_df, tokenizer, max_length=128)\n    val_dataset = MixedTrainingDataset(val_df, tokenizer, max_length=128)\n    \n    print(f\"Training on {len(train_dataset)} examples ({len(train_df)} situations \u00d7 3 modes)\")\n    print(f\"Validation on {len(val_dataset)} examples ({len(val_df)} situations \u00d7 3 modes)\")\n    print(\"Mixed training: 1 pairwise + 2 single-input examples per situation\")\n    \n    # Training arguments with GPU optimizations\n    training_args = TrainingArguments(\n        output_dir=\"./risk_averse_model\",\n        num_train_epochs=3,\n        per_device_train_batch_size=1,  # Reduced from 2 for T4 GPU memory\n        per_device_eval_batch_size=4,\n        gradient_accumulation_steps=2,\n        warmup_steps=100,\n        weight_decay=0.01,\n        logging_dir=\"./logs\",\n        logging_steps=50,\n        report_to=\"none\",  # Disable wandb and other external loggers\n        eval_strategy=\"steps\",\n        eval_steps=200,\n        save_steps=200,\n        load_best_model_at_end=False,\n        fp16=True,\n        dataloader_pin_memory=True,\n        dataloader_num_workers=2,\n        remove_unused_columns=False,\n        optim=\"adamw_torch_fused\",\n        prediction_loss_only=True,\n    )\n    \n    # Mixed data collator (handles both pairwise and single-input batches)\n    data_collator = MixedDataCollator(tokenizer)\n    \n    # Trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        data_collator=data_collator,\n    )\n    \n    # Validate setup\n    print(\"Validating model setup...\")\n    sample_batch = next(iter(DataLoader(train_dataset, batch_size=1, collate_fn=data_collator)))\n    model.train()\n    \n    try:\n        with torch.no_grad():\n            outputs = model(**sample_batch)\n            print(f\"\u2713 Model forward pass successful. Loss: {outputs['loss'].item():.3f}\")\n    except Exception as e:\n        print(f\"\u2717 Model validation failed: {e}\")\n        raise\n    \n    # Train\n    print(\"Starting pairwise ranking training...\")\n    trainer.train()\n    \n    return model, tokenizer, trainer\n\nprint(\"\u2713 Training function defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Main Experiment Function\n",
    "\n",
    "Orchestrates the complete experiment from data loading to visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    \"\"\"Run the complete risk aversion experiment\"\"\"\n",
    "    print(\"=== Risk-Averse Reward Model Experiment ===\")\n",
    "    print(f\"PyTorch device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    \n",
    "    # Load data from CSV\n",
    "    print(\"\\n1. Loading risk scenario data from CSV...\")\n",
    "    loader = RiskAversionDataLoader()\n",
    "    full_dataset_df = loader.load_and_process_data()\n",
    "    \n",
    "    # Limit to 500 situations for training\n",
    "    if len(full_dataset_df) > 500:\n",
    "        dataset_df = full_dataset_df.head(500)\n",
    "        print(f\"Limited dataset to {len(dataset_df)} situations for training\")\n",
    "    else:\n",
    "        dataset_df = full_dataset_df\n",
    "        print(f\"Using all {len(dataset_df)} available situations\")\n",
    "    \n",
    "    # Split into train/test\n",
    "    train_df, test_df = train_test_split(dataset_df, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\n2. Training reward model...\")\n",
    "    model, tokenizer, trainer = train_reward_model(train_df)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"\\n3. Evaluating model...\")\n",
    "    accuracy, eval_results = evaluate_model(model, tokenizer, test_df, return_detailed=True)\n",
    "    \n",
    "    # Plot results\n",
    "    print(f\"\\n4. Creating visualizations...\")\n",
    "    plot_results(trainer, eval_results, accuracy)\n",
    "    \n",
    "    # Save results\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    results = {\n",
    "        \"num_training_situations\": len(train_df),\n",
    "        \"num_test_situations\": len(test_df),\n",
    "        \"final_accuracy\": accuracy,\n",
    "        \"risk_averse_preference_rate\": eval_results['risk_averse_preference_rate'],\n",
    "        \"model_name\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(\"outputs/experiment_results.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n=== Experiment Complete ===\")\n",
    "    print(f\"Results saved to outputs/experiment_results.json\")\n",
    "    print(f\"Final accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Risk-averse preference rate: {eval_results['risk_averse_preference_rate']:.3f}\")\n",
    "    \n",
    "    risk_averse_scores = np.array(eval_results['risk_averse_scores'])\n",
    "    risk_neutral_scores = np.array(eval_results['risk_neutral_scores'])\n",
    "    score_difference = np.mean(risk_averse_scores) - np.mean(risk_neutral_scores)\n",
    "    print(f\"Average score difference (risk-averse - risk-neutral): {score_difference:+.3f}\")\n",
    "    \n",
    "    return model, tokenizer, results\n",
    "\n",
    "print(\"\u2713 Main experiment function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run the Experiment\n",
    "\n",
    "Execute the complete training and evaluation pipeline.\n",
    "\n",
    "**Before running:** Ensure you have uploaded `strict_disagreements_10k_with_prompts_and_bad_formats.csv` to this Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiment\n",
    "try:\n",
    "    model, tokenizer, results = run_experiment()\n",
    "    print(\"\\n\u2713 Experiment completed successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n\u2717 Error: {e}\")\n",
    "    print(\"Please upload 'strict_disagreements_10k_with_prompts_and_bad_formats.csv' to Colab.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n\u2717 Experiment failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test Model on Sample Scenario (Optional)\n",
    "\n",
    "Run inference on a specific scenario to see how the model scores different options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test on a specific example (optional - run after experiment completes)\ntry:\n    loader = RiskAversionDataLoader()\n    dataset_df = loader.load_and_process_data()\n    test_row = dataset_df.iloc[0]\n    \n    print(\"Test scenario:\")\n    print(test_row['prompt_text'])\n    print(f\"\\nRisk-averse choice: {test_row['correct_label']}\")\n    print(f\"Risk-neutral choice: {test_row['incorrect_label']}\")\n    \n    model.eval()\n    device = next(model.parameters()).device\n    \n    with torch.no_grad():\n        for option_type, option in [(\"Risk-averse\", test_row['correct_label']), \n                                    (\"Risk-neutral\", test_row['incorrect_label'])]:\n            input_text = f\"{test_row['prompt_text']}\\n\\nChosen option: {option}\"\n            encoding = tokenizer(input_text, truncation=True, padding='max_length', \n                               max_length=128, return_tensors='pt')\n            encoding = {k: v.to(device) for k, v in encoding.items()}\n            outputs = model(**encoding)\n            score = outputs[\"logits\"].item()\n            sigmoid_score = torch.sigmoid(torch.tensor(score)).item()\n            print(f\"\\n{option_type} option {option}:\")\n            print(f\"  Raw score: {score:.3f}\")\n            print(f\"  Sigmoid score: {sigmoid_score:.3f}\")\nexcept Exception as e:\n    print(f\"Test failed: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Download Results (Optional)\n",
    "\n",
    "Download the results and plots from Colab to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results (optional)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    \n",
    "    # Download experiment results JSON\n",
    "    if os.path.exists(\"outputs/experiment_results.json\"):\n",
    "        files.download(\"outputs/experiment_results.json\")\n",
    "    \n",
    "    # Download the latest plot\n",
    "    import glob\n",
    "    plot_files = glob.glob(\"outputs/training_results_*.png\")\n",
    "    if plot_files:\n",
    "        latest_plot = max(plot_files, key=os.path.getctime)\n",
    "        files.download(latest_plot)\n",
    "        print(f\"Downloaded: {latest_plot}\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Colab - skip download\")\n",
    "except Exception as e:\n",
    "    print(f\"Download failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}