{
  "train_loss": [
    0.6454114399850368,
    0.5885633815079927,
    0.5631399703770876,
    0.5402032331516966,
    0.435303619178012,
    0.43760739171411844,
    0.43106077387618524,
    0.4414470431348309,
    0.4355647826846689,
    0.39223244533175605,
    0.38891540981576933,
    0.3863538206879457,
    0.42825730478798507,
    0.41477443871001013,
    0.3917237085788899,
    0.38874795526979145,
    0.3341013086814201,
    0.37589285965746966,
    0.363776723992972,
    0.36084257968264866
  ],
  "train_steps": [
    100,
    200,
    300,
    400,
    500,
    600,
    700,
    800,
    900,
    1000,
    1100,
    1200,
    1300,
    1400,
    1500,
    1600,
    1700,
    1800,
    1900,
    2000
  ],
  "val_accuracy": [
    0.55,
    0.625,
    0.545,
    0.605,
    0.6
  ],
  "val_loss": [
    0.4818656247854233,
    0.3871326980739832,
    0.6169944755174219,
    0.382436229288578,
    0.38021701328456403
  ],
  "epochs": [
    1,
    2,
    3,
    4,
    5
  ],
  "reward_margins": [
    0.8050875142402947,
    1.4673020966351031,
    1.896354932449758,
    2.179584005177021,
    2.2524477256834508
  ],
  "preferred_rewards": [
    -2.3754971633572133,
    -2.912565822531469,
    -1.2466034053533803,
    -1.5128419601928909,
    -1.0152701002894902
  ],
  "rejected_rewards": [
    -3.180584677560255,
    -4.3798679179186,
    -3.142958338634344,
    -3.6924259648215956,
    -3.267717826596927
  ]
}