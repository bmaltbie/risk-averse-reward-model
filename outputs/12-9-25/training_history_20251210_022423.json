{
  "train_loss": [
    0.7714260596036911,
    0.6683481884002686,
    0.44352773398160933,
    0.29443997284019136,
    0.24165272344338518,
    0.20162404931153077,
    0.4220457874460425,
    0.2749627919262275,
    0.20129036437583636,
    0.1951046731414911
  ],
  "train_steps": [
    50,
    100,
    150,
    200,
    250,
    300,
    350,
    400,
    450,
    500
  ],
  "val_accuracy": [
    0.30673316708229426,
    0.33915211970074816,
    0.3266832917705736,
    0.33665835411471323,
    0.3491271820448878,
    0.3092269326683292,
    0.28428927680798005,
    0.4089775561097257,
    0.4014962593516209,
    0.39900249376558605
  ],
  "val_loss": [
    0.7065982218097867,
    0.6781276413924676,
    0.8253806636220499,
    0.6887250261711063,
    1.3886256543478168,
    2.216466199207187,
    0.8918199231499746,
    0.7772060601491286,
    1.0654045335967046,
    1.110108344780834
  ],
  "epochs": [
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10
  ],
  "reward_margins": [
    -0.06244488626718521,
    0.12840968176722525,
    1.1223386153578758,
    4.064694342315197,
    3.632070882320404,
    9.259787372350694,
    5.011056205332279,
    2.742243868410587,
    6.233580529391766,
    7.805095131397247
  ],
  "preferred_rewards": [
    -1.3292875495553016,
    -0.007132402509450912,
    0.8455559063702822,
    3.9026178874075415,
    2.294061921387911,
    7.433046413064003,
    3.531643152087927,
    0.4734956543892622,
    2.765100394636393,
    3.9710022205114366
  ],
  "rejected_rewards": [
    -1.2668426622450353,
    -0.13554208636283874,
    -0.27678272090852263,
    -0.1620764370262623,
    -1.3380089643597604,
    -1.826740943491459,
    -1.4794130124151708,
    -2.2687482273578645,
    -3.468480132818222,
    -3.8340929067134857
  ]
}